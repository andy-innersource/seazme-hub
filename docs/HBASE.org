* Design priciples:

 - add only, never delete, never update
 - or upsert only in some cases
 - meta: apikey:user appid, ts ...
 - CF with "table name" or "self" (like in Python :-) )
 - CF with meta
 - CF since all is immutable, we can always have a copy
 - uuid is unique accross machines
 - UTC for formatted timestamps (I know it is not human readable, but machine redability counts too :-) )


* Tables

#+BEGIN_SRC

common:
    meta=meta(id, key, created, headers, comment)

apps: ;list of all integrations
  uuid:
      self: expires, description, kind, bu, instance, notification-contacts[email/sms/slack], base-url, <meta>

intake-sessions: ;fast scan by time
  ts/uuid(|/submit|/cancel):
      self: expires, command:scan/update/patch, ?count (for submit), description, time-span, time-offset, range, <meta>
      app: <copy-of-apps>

intake-data: ;fast scan by session (or session with 00-FF(or higer) prefix for better use of regions)
  256based-random-2digit-hex/uuid/path:
      self: payload, type, <meta>
      app: <copy-of-apps>
      session: <copy-of-session>

datahub:
  reversed-jira-id: ;fast lookup by jira-id
      hive: <mapping-based-transfomation-of-payload>
      datahub: id, key updated, status, meta, payload

datahub:datahub:snapshot-update-log
  <:prefix>-<(format "%011x" (bit-not created))> ;fast reverse scan by prefix
      self: app2scan, app2update, meta
#+END_SRC

* Scripts

#+BEGIN_SRC

list 'datahub:.*'

scan "datahub:apps"

truncate 'datahub:apps'
truncate 'datahub:intake-sessions'
truncate 'datahub:intake-data'

count 'datahub:intake-data', INTERVAL => 1000000
$ hbase org.apache.hadoop.hbase.mapreduce.RowCounter "datahub:intake-data"
scan 'datahub:intake-data', {'LIMIT' => 5}
scan 'datahub:intake-data', {COLUMNS => 'self:meta', STARTROW => "<2dig-hex-prefix>\\<session-id>", 'LIMIT' => 5}

describe "datahub:snapshot-data"
scan 'datahub:snapshot-data', {'LIMIT' => 5}
scan 'datahub:snapshot-data', {COLUMNS => 'hive', 'LIMIT' => 2}
scan 'datahub:snapshot-data', {COLUMNS => '<CF>:<mapped-field>', 'LIMIT' => 50}
get 'datahub:snapshot-data', '1234567'.reverse! # the key should be reversed
deleteall 'datahub:snapshot-data', '1234567'.reverse! # the key should be reversed

disable 'datahub:intake-sessions'
enable 'datahub:intake-sessions'
disable 'datahub:intake-data'
enable 'datahub:intake-data'

disable 'datahub:intake-sessions'
drop 'datahub:intake-sessions'
disable 'datahub:intake-data'
drop 'datahub:intake-data'

create 'datahub:apps', 'self'
create 'datahub:intake-sessions', 'self', 'app'
create 'datahub:intake-data', 'self', 'app', 'session'

create 'datahub:snapshot-data', 'datahub', 'hive'
create 'datahub:snapshot-update-log', 'self'
count 'datahub:snapshot-update-log', INTERVAL=> 1

alter 'datahub:<table>', '<new CF>'

print "rename datahub:intake-sessions\n"
disable 'datahub:intake-sessions'
snapshot 'datahub:intake-sessions', 'intake-sessions-snap'
clone_snapshot 'intake-sessions-snap', 'datahub:intake-sessions-1'
drop 'datahub:intake-sessions'
print "ask admins to run below\n"
delete_snapshot 'intake-sessions-snap'

#+END_SRC

* Resources
 - similar to http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html
 - http://hbase.apache.org/book.html#rowkey.design - critical
 - http://hadooptutorial.info/hbase-shell-commands-in-practice/
